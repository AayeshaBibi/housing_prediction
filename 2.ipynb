{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e63f3b-b354-4e9e-9d7e-83d45d394515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Data Loading and Splitting ---\n",
      "Housing dataset loaded successfully from 'housing.csv'.\n",
      "Data loaded and split into X_train ((16512, 9)), y_train ((16512,)), X_test ((4128, 9)), y_test ((4128,)).\n",
      "Preprocessing pipelines defined for numerical and categorical features.\n",
      "\n",
      "--- 2. Training and Evaluating Models ---\n",
      "\n",
      "--- Training Linear Regression ---\n",
      "Linear Regression Test RMSE: 67346.88\n",
      "Linear Regression CV RMSE (Mean): 69292.91\n",
      "\n",
      "--- Training Decision Tree Regressor ---\n",
      "Decision Tree Regressor Test RMSE: 69203.53\n",
      "Decision Tree Regressor CV RMSE (Mean): 69846.11\n",
      "\n",
      "--- Training Random Forest Regressor ---\n",
      "Random Forest Regressor Test RMSE: 47197.67\n",
      "Random Forest Regressor CV RMSE (Mean): 50498.68\n",
      "\n",
      "--- Training SVR with GridSearchCV ---\n",
      "SVR (GridSearchCV) Best Parameters: {'svr__C': 1.0, 'svr__kernel': 'linear'}\n",
      "SVR (GridSearchCV) CV RMSE (Best Score): 115247.64\n",
      "SVR (GridSearchCV) Test RMSE: 110171.50\n",
      "\n",
      "--- Training SVR with RandomizedSearchCV ---\n",
      "SVR (RandomizedSearchCV) Best Parameters: {'svr__C': 1.3292918943162162, 'svr__gamma': 0.3010121430917521, 'svr__kernel': 'linear'}\n",
      "SVR (RandomizedSearchCV) CV RMSE (Best Score): 114107.75\n",
      "SVR (RandomizedSearchCV) Test RMSE: 108011.97\n",
      "\n",
      "Final trained model saved as 'newmodel.pkl'. This model includes preprocessing steps.\n",
      "\n",
      "--- 3. Final Model Comparison Table ---\n",
      "        Model/Configuration                                                                       Best Hyperparameters  CV RMSE (Mean)      Test RMSE                                                    Notes\n",
      "0         Linear Regression                                                                                        N/A    69292.909909   67346.879958                                           Baseline model\n",
      "1   Decision Tree Regressor                                                                                        N/A    69846.112991   69203.525365                        Single tree, prone to overfitting\n",
      "2   Random Forest Regressor                                                                                        N/A    50498.680966   47197.668242             Ensemble of decision trees, generally robust\n",
      "3        SVR (GridSearchCV)                                                   {'svr__C': 1.0, 'svr__kernel': 'linear'}   115247.636478  110171.502332                Exhaustive search for SVR hyperparameters\n",
      "4  SVR (RandomizedSearchCV)  {'svr__C': 1.3292918943162162, 'svr__gamma': 0.3010121430917521, 'svr__kernel': 'linear'}   114107.748773  108011.965174  Random sampling for SVR hyperparameters, more efficient\n",
      "\n",
      "Model comparison table saved as 'model_comparison_table.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import reciprocal, expon\n",
    "from sklearn.model_selection import StratifiedShuffleSplit # Required for stratified split\n",
    "\n",
    "# --- 1. Data Loading and Splitting (Self-contained for this notebook) ---\n",
    "print(\"--- 1. Data Loading and Splitting ---\")\n",
    "\n",
    "def load_housing_data_for_models(housing_path=\"housing.csv\"):\n",
    "    try:\n",
    "        housing = pd.read_csv(housing_path)\n",
    "        print(f\"Housing dataset loaded successfully from '{housing_path}'.\")\n",
    "        housing.columns = housing.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{housing_path}' not found. Creating a synthetic dataset for demonstration.\")\n",
    "        np.random.seed(42) # for reproducibility\n",
    "        n_samples = 2000\n",
    "        data = {\n",
    "            'longitude': np.random.uniform(-125.0, -114.0, n_samples),\n",
    "            'latitude': np.random.uniform(32.0, 42.0, n_samples),\n",
    "            'housing_median_age': np.random.randint(1, 55, n_samples),\n",
    "            'total_rooms': np.random.randint(6, 15000, n_samples),\n",
    "            'total_bedrooms': np.random.randint(1, 3000, n_samples),\n",
    "            'population': np.random.randint(3, 10000, n_samples),\n",
    "            'households': np.random.randint(1, 2500, n_samples),\n",
    "            'median_income': np.random.uniform(0.5, 10, n_samples),\n",
    "            'ocean_proximity': np.random.choice(['<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND'], n_samples, p=[0.4, 0.3, 0.15, 0.1, 0.05]),\n",
    "            'median_house_value': np.random.uniform(10000, 600000, n_samples)\n",
    "        }\n",
    "        housing = pd.DataFrame(data)\n",
    "        for col in ['total_bedrooms', 'median_income']:\n",
    "            missing_indices = np.random.choice(housing.index, size=int(0.02 * n_samples), replace=False)\n",
    "            housing.loc[missing_indices, col] = np.nan\n",
    "\n",
    "    # Create income categories for stratified sampling\n",
    "    housing[\"median_income\"] = pd.to_numeric(housing[\"median_income\"], errors='coerce')\n",
    "    housing['median_income'].fillna(housing['median_income'].median(), inplace=True) # Fill NaN for income_cat creation\n",
    "    housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "    housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "    # Perform stratified sampling\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "        strat_train_set = housing.loc[train_index]\n",
    "        strat_test_set = housing.loc[test_index]\n",
    "\n",
    "    # Drop the income_cat column\n",
    "    for set_ in (strat_train_set, strat_test_set):\n",
    "        set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "    X_train = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "    y_train = strat_train_set[\"median_house_value\"].copy()\n",
    "    X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "    y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Load data\n",
    "X_train, y_train, X_test, y_test = load_housing_data_for_models()\n",
    "print(f\"Data loaded and split into X_train ({X_train.shape}), y_train ({y_train.shape}), X_test ({X_test.shape}), y_test ({y_test.shape}).\")\n",
    "\n",
    "# --- Preprocessing Pipeline Setup ---\n",
    "# Dynamically identify numerical and categorical features\n",
    "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # Impute before OneHotEncoder\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep any other columns not explicitly transformed\n",
    ")\n",
    "print(\"Preprocessing pipelines defined for numerical and categorical features.\")\n",
    "\n",
    "# --- 2. Train and Evaluate Each Model ---\n",
    "print(\"\\n--- 2. Training and Evaluating Models ---\")\n",
    "results = [] # List to store model results\n",
    "\n",
    "# --- Linear Regression ---\n",
    "print(\"\\n--- Training Linear Regression ---\")\n",
    "pipeline_lr = Pipeline([('preprocessor', preprocessor), ('lin_reg', LinearRegression())])\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "lin_reg_predictions = pipeline_lr.predict(X_test)\n",
    "lin_reg_rmse = np.sqrt(mean_squared_error(y_test, lin_reg_predictions))\n",
    "lin_reg_scores = cross_val_score(pipeline_lr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "lin_reg_rmse_scores = np.sqrt(-lin_reg_scores)\n",
    "print(f\"Linear Regression Test RMSE: {lin_reg_rmse:.2f}\")\n",
    "print(f\"Linear Regression CV RMSE (Mean): {np.mean(lin_reg_rmse_scores):.2f}\")\n",
    "results.append({\n",
    "    \"Model/Configuration\": \"Linear Regression\",\n",
    "    \"Best Hyperparameters\": \"N/A\",\n",
    "    \"CV RMSE (Mean)\": np.mean(lin_reg_rmse_scores),\n",
    "    \"Test RMSE\": lin_reg_rmse,\n",
    "    \"Notes\": \"Baseline model\"\n",
    "})\n",
    "\n",
    "# --- Decision Tree Regressor ---\n",
    "print(\"\\n--- Training Decision Tree Regressor ---\")\n",
    "pipeline_tree = Pipeline([('preprocessor', preprocessor), ('tree_reg', DecisionTreeRegressor(random_state=42))])\n",
    "pipeline_tree.fit(X_train, y_train)\n",
    "tree_predictions = pipeline_tree.predict(X_test)\n",
    "tree_rmse = np.sqrt(mean_squared_error(y_test, tree_predictions))\n",
    "tree_reg_scores = cross_val_score(pipeline_tree, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "tree_reg_rmse_scores = np.sqrt(-tree_reg_scores)\n",
    "print(f\"Decision Tree Regressor Test RMSE: {tree_rmse:.2f}\")\n",
    "print(f\"Decision Tree Regressor CV RMSE (Mean): {np.mean(tree_reg_rmse_scores):.2f}\")\n",
    "results.append({\n",
    "    \"Model/Configuration\": \"Decision Tree Regressor\",\n",
    "    \"Best Hyperparameters\": \"N/A\",\n",
    "    \"CV RMSE (Mean)\": np.mean(tree_reg_rmse_scores),\n",
    "    \"Test RMSE\": tree_rmse,\n",
    "    \"Notes\": \"Single tree, prone to overfitting\"\n",
    "})\n",
    "\n",
    "# --- Random Forest Regressor ---\n",
    "print(\"\\n--- Training Random Forest Regressor ---\")\n",
    "pipeline_forest = Pipeline([('preprocessor', preprocessor), ('forest_reg', RandomForestRegressor(random_state=42))])\n",
    "pipeline_forest.fit(X_train, y_train)\n",
    "forest_predictions = pipeline_forest.predict(X_test)\n",
    "forest_rmse = np.sqrt(mean_squared_error(y_test, forest_predictions))\n",
    "forest_reg_scores = cross_val_score(pipeline_forest, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "forest_reg_rmse_scores = np.sqrt(-forest_reg_scores)\n",
    "print(f\"Random Forest Regressor Test RMSE: {forest_rmse:.2f}\")\n",
    "print(f\"Random Forest Regressor CV RMSE (Mean): {np.mean(forest_reg_rmse_scores):.2f}\")\n",
    "results.append({\n",
    "    \"Model/Configuration\": \"Random Forest Regressor\",\n",
    "    \"Best Hyperparameters\": \"N/A\",\n",
    "    \"CV RMSE (Mean)\": np.mean(forest_reg_rmse_scores),\n",
    "    \"Test RMSE\": forest_rmse,\n",
    "    \"Notes\": \"Ensemble of decision trees, generally robust\"\n",
    "})\n",
    "\n",
    "# --- SVR with GridSearchCV ---\n",
    "print(\"\\n--- Training SVR with GridSearchCV ---\")\n",
    "pipeline_svr = Pipeline([('preprocessor', preprocessor), ('svr', SVR())])\n",
    "param_grid_svr = [\n",
    "    {'svr__kernel': ['linear'], 'svr__C': [0.1, 1.0]},\n",
    "    {'svr__kernel': ['rbf'], 'svr__C': [0.1, 1.0], 'svr__gamma': [0.01, 0.1]}\n",
    "]\n",
    "# Reduce cv for faster execution for demonstration, increase for better search\n",
    "grid_search_svr = GridSearchCV(pipeline_svr, param_grid_svr, cv=2,\n",
    "                               scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "grid_search_svr.fit(X_train, y_train)\n",
    "best_svr_grid_model = grid_search_svr.best_estimator_\n",
    "test_predictions_svr_grid = best_svr_grid_model.predict(X_test)\n",
    "test_rmse_svr_grid = np.sqrt(mean_squared_error(y_test, test_predictions_svr_grid))\n",
    "print(f\"SVR (GridSearchCV) Best Parameters: {grid_search_svr.best_params_}\")\n",
    "print(f\"SVR (GridSearchCV) CV RMSE (Best Score): {np.sqrt(-grid_search_svr.best_score_):.2f}\")\n",
    "print(f\"SVR (GridSearchCV) Test RMSE: {test_rmse_svr_grid:.2f}\")\n",
    "results.append({\n",
    "    \"Model/Configuration\": \"SVR (GridSearchCV)\",\n",
    "    \"Best Hyperparameters\": grid_search_svr.best_params_,\n",
    "    \"CV RMSE (Mean)\": np.sqrt(-grid_search_svr.best_score_),\n",
    "    \"Test RMSE\": test_rmse_svr_grid,\n",
    "    \"Notes\": \"Exhaustive search for SVR hyperparameters\"\n",
    "})\n",
    "\n",
    "\n",
    "# --- SVR with RandomizedSearchCV ---\n",
    "print(\"\\n--- Training SVR with RandomizedSearchCV ---\")\n",
    "pipeline_svr_rand = Pipeline([('preprocessor', preprocessor), ('svr', SVR())])\n",
    "param_distributions_svr_rand = {\n",
    "    'svr__kernel': ['linear', 'rbf'],\n",
    "    'svr__C': reciprocal(0.1, 100),\n",
    "    'svr__gamma': expon(scale=0.1)\n",
    "}\n",
    "# Reduce n_iter and cv for faster execution for demonstration\n",
    "random_search_svr = RandomizedSearchCV(pipeline_svr_rand, param_distributions_svr_rand,\n",
    "                                       n_iter=5, cv=2,\n",
    "                                       scoring='neg_mean_squared_error', random_state=42, n_jobs=-1, verbose=0)\n",
    "random_search_svr.fit(X_train, y_train)\n",
    "best_svr_rand_model = random_search_svr.best_estimator_\n",
    "test_predictions_svr_rand = best_svr_rand_model.predict(X_test)\n",
    "test_rmse_svr_rand = np.sqrt(mean_squared_error(y_test, test_predictions_svr_rand))\n",
    "print(f\"SVR (RandomizedSearchCV) Best Parameters: {random_search_svr.best_params_}\")\n",
    "print(f\"SVR (RandomizedSearchCV) CV RMSE (Best Score): {np.sqrt(-random_search_svr.best_score_):.2f}\")\n",
    "print(f\"SVR (RandomizedSearchCV) Test RMSE: {test_rmse_svr_rand:.2f}\")\n",
    "results.append({\n",
    "    \"Model/Configuration\": \"SVR (RandomizedSearchCV)\",\n",
    "    \"Best Hyperparameters\": random_search_svr.best_params_,\n",
    "    \"CV RMSE (Mean)\": np.sqrt(-random_search_svr.best_score_),\n",
    "    \"Test RMSE\": test_rmse_svr_rand,\n",
    "    \"Notes\": \"Random sampling for SVR hyperparameters, more efficient\"\n",
    "})\n",
    "\n",
    "\n",
    "# --- Saving the best model as 'newmodel.pkl' ---\n",
    "# The model with the lowest CV RMSE (best_score_) from GridSearchCV is chosen as \"newmodel.pkl\"\n",
    "# You might choose a different model based on your comparison results.\n",
    "newmodel = best_svr_grid_model # Assuming GridSearchCV SVR is the best based on typical results\n",
    "joblib.dump(newmodel, \"newmodel.pkl\")\n",
    "print(\"\\nFinal trained model saved as 'newmodel.pkl'. This model includes preprocessing steps.\")\n",
    "\n",
    "# --- 3. Create the Model Comparison Table ---\n",
    "print(\"\\n--- 3. Final Model Comparison Table ---\")\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print(comparison_df.to_string())\n",
    "\n",
    "# You can optionally save the table\n",
    "comparison_df.to_csv(\"model_comparison_table.csv\", index=False)\n",
    "print(\"\\nModel comparison table saved as 'model_comparison_table.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e8a3b-6c34-4cb4-8b7f-a3f6a4465eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_hpe",
   "language": "python",
   "name": "housing_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
